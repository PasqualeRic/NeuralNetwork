{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10190077,"sourceType":"datasetVersion","datasetId":6295778},{"sourceId":10190185,"sourceType":"datasetVersion","datasetId":6295862},{"sourceId":198058,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":168920,"modelId":191272},{"sourceId":198059,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":168921,"modelId":191273},{"sourceId":198074,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":168931,"modelId":191283},{"sourceId":198170,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":169018,"modelId":191369}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport glob\nfrom scipy.signal import butter, filtfilt\nfrom scipy.signal import resample_poly\nimport librosa\nimport pickle\nfrom collections import Counter\nimport warnings\nfrom scipy.io import loadmat\nimport random\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#riduzione dataset seed\n\ninput_path = '/kaggle/input/seed-dataset/Preprocessed_EEG'\noutput_path = '/kaggle/working/reduced_dataset'\n\nos.makedirs(output_path, exist_ok=True)\n\n# Parametri per la riduzione\nchannel_reduction_ratio = 3  # Dividi il numero di canali per 3\nsample_reduction_ratio = 2   # Dividi il numero di campioni per 2\n\nmat_files = [f for f in os.listdir(input_path) if f.endswith('.mat') and f != 'label.mat']\nprint(f\"Trovati {len(mat_files)} file .mat nella directory.\")\n\nfor file_name in mat_files:\n    file_path = os.path.join(input_path, file_name)\n    print(f\"Processando il file: {file_name}\")\n    \n    mat_data = loadmat(file_path)\n    \n    # Trova tutte le chiavi che rappresentano trial (chiavi con strutture comuni come djc_eeg, ys_eeg, ecc.)\n    trial_keys = [key for key in sorted(mat_data.keys()) if not key.startswith('__') and isinstance(mat_data[key], np.ndarray)]\n    print(f\"Trial trovati in {file_name}: {trial_keys}\")\n    \n    if not trial_keys:\n        print(f\"Nessun trial trovato in {file_name}, salto il file.\")\n        continue\n    \n    # Seleziona casualmente un terzo dei trial\n    random.seed(42) \n    selected_keys = random.sample(trial_keys, len(trial_keys) // 3)\n    \n    for key in selected_keys:  # Itera SOLO sui trial selezionati\n        data = mat_data[key]\n        \n        # Riduzione del numero di canali\n        num_channels = data.shape[0]\n        reduced_channels = num_channels // channel_reduction_ratio\n        reduced_data = data[:reduced_channels, :]\n        \n        # Riduzione del numero di campioni\n        num_samples = reduced_data.shape[1]\n        reduced_samples = num_samples // sample_reduction_ratio\n        reduced_data = reduced_data[:, :reduced_samples]\n        \n        output_file = os.path.join(output_path, f\"{file_name.replace('.mat', '')}_{key}.npz\")\n        np.savez(output_file, data=reduced_data)\n\nprint(f\"Dataset ridotto salvato in: {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Preprocessamente per epoche da 1 secondo\ninput_folder = '/kaggle/working/reduced_dataset'\noutput_folder = '/kaggle/working/preprocessed_1_sec'\nos.makedirs(output_folder, exist_ok=True)\n\n# Ignora i warning\nwarnings.filterwarnings(\"ignore\")\n\n# Parametri per la segmentazione e il filtro\nfs = 200  # Frequenza di campionamento in Hz\nepoch_length = fs  # Campioni in 1 secondo (200 campioni per 200 Hz)\nupper_limit = 500  # Valore massimo per la pulizia del segnale\n\n# Etichette definite\nlabels = [1, 0, -1, -1, 0, 1, -1, 0, 1, 1, 0, -1, 0, 1, -1]  # 15 etichette\n\n# Funzione per il filtro band-pass Butterworth\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\ndef plot_signals(original_signal, cleaned_signal, channel_idx, file_name):\n    plt.figure(figsize=(15, 10))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(original_signal, label='Originale', color='blue')\n    plt.title(f\"{file_name} - Canale {channel_idx} (Originale)\")\n    plt.xlabel(\"Campioni\")\n    plt.ylabel(\"Ampiezza\")\n    plt.legend()\n\n    plt.subplot(2, 1, 2)\n    plt.plot(cleaned_signal, label='Pulito (±500 µV)', color='red')\n    plt.title(f\"{file_name} - Canale {channel_idx} (Pulito)\")\n    plt.xlabel(\"Campioni\")\n    plt.ylabel(\"Ampiezza\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\nfile_paths = glob.glob(f\"{input_folder}/*.npz\")  # File di input\n\nfor file_path in file_paths:\n    try:\n        # Carica il file .npz\n        file_name = os.path.basename(file_path).replace('.npz', '')\n        print(f\"Processando il file: {file_name}\")\n\n        npz_data = np.load(file_path)\n        \n        for key in npz_data.keys():\n            data = npz_data[key]  # Forma: (n_channels, n_samples)\n            print(f\"Elaborazione della chiave: {key} - Forma: {data.shape}\")\n            \n            # Epoche di 1 secondo\n            n_channels, n_samples = data.shape\n            n_epochs = n_samples // epoch_length  # Numero di epoche complete\n            epochs = []\n\n            for i in range(n_epochs):\n                start_idx = i * epoch_length\n                end_idx = start_idx + epoch_length\n                epoch = data[:, start_idx:end_idx]  # Estrai epoca\n\n                # Pulizia del segnale (valori superiori a ±500 µV)\n                epoch[epoch > upper_limit] = 0\n\n                epochs.append(epoch)\n\n            epochs = np.array(epochs)  # Forma: (n_epochs, n_channels, epoch_length)\n            print(f\"Dati suddivisi in epoche per la chiave {key}: {epochs.shape}\")\n\n            # Estrazione del numero per la label\n            file_number = int(file_name.split('_')[0])  # Prendi il numero del file\n            print(file_number)\n            label_index = (file_number - 1) % len(labels)\n            label = labels[label_index]\n\n            output_path = os.path.join(output_folder, f\"processed_{file_name}_{key}.npz\")\n            np.savez(output_path, data=epochs, label=label)\n            print(f\"File salvato con etichetta {label} in: {output_path}\")\n\n    except Exception as e:\n        print(f\"Errore durante il preprocessing del file {file_path}: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Split del dataset per train e test\n\ninput_folder = '/kaggle/working/preprocessed_1_sec'\ntrain_folder = '/kaggle/working/train_set'\ntest_folder = '/kaggle/working/test_set'\nos.makedirs(train_folder, exist_ok=True)\nos.makedirs(test_folder, exist_ok=True)\n\n# Ignora i warning\nwarnings.filterwarnings(\"ignore\")\n\nfile_paths = glob.glob(f\"{input_folder}/*.npz\")\nprint(f\"Trovati {len(file_paths)} file nel dataset elaborato.\")\n\n# Suddivisione in train e test\ntrain_files, test_files = train_test_split(file_paths, test_size=0.2, random_state=42)\nprint(f\"File di train: {len(train_files)}, File di test: {len(test_files)}\")\n\n# Funzione per spostare i file nelle rispettive cartelle\ndef save_files(file_list, destination_folder):\n    for file_path in file_list:\n        file_name = os.path.basename(file_path)\n        destination_path = os.path.join(destination_folder, file_name)\n        os.rename(file_path, destination_path)\n        print(f\"File spostato: {file_name} -> {destination_folder}\")\n\nsave_files(train_files, train_folder)\nsave_files(test_files, test_folder)\n\nprint(\"Divisione in train e test completata.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FASE DI PREPROCESSING E REORDERING DEI FILE IN COLONNE**","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"# ------------------- Funzioni per Salvare e Caricare Modelli -------------------\nsave_path = \"/kaggle/working/models\"\nos.makedirs(save_path, exist_ok=True)\n\ndef save_model(model, path):\n    torch.save(model.state_dict(), path)\n    print(f\"Modello salvato in {path}\")\n\n\n#tolgo il module \ndef load_model(model, path, device=\"cuda\"):\n    state_dict = torch.load(path, map_location=device)\n    if \"module.\" in list(state_dict.keys())[0]:\n        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict)\n    print(f\"Modello caricato da {path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FASE DI TRAINING DELL'ENCODER RICORRENTE E CONVOLUZIONALE**","metadata":{}},{"cell_type":"markdown","source":"********","metadata":{}},{"cell_type":"code","source":"#AUGMENTATION E CHUNK DATI\ndef min_max_amplitude_scale(data, scale_min=0.5, scale_max=2):\n    scale_factor = random.uniform(scale_min, scale_max)\n    return data * scale_factor\n\ndef time_shift(data, shift_min=-50, shift_max=50):\n    shift_samples = random.randint(shift_min, shift_max)\n    return np.roll(data, shift_samples)\n\ndef dc_shift(data, shift_min=-10, shift_max=10):\n    shift_value = random.uniform(shift_min, shift_max)\n    return data + shift_value\n\ndef zero_masking(data, mask_min=0, mask_max=150):\n    mask_size = random.randint(mask_min, mask_max)\n    start_idx = random.randint(0, len(data) - mask_size)\n    data[start_idx:start_idx+mask_size] = 0\n    return data\n\ndef add_gaussian_noise(data, sigma_min=0, sigma_max=0.2):\n    sigma = random.uniform(sigma_min, sigma_max)\n    noise = np.random.normal(0, sigma, len(data))\n    return data + noise\n\ndef apply_random_transformations_class(channel_data):\n    transformations = [min_max_amplitude_scale, time_shift, dc_shift, zero_masking, add_gaussian_noise]\n    selected_transform = random.choice(transformations)\n    transformed_data = selected_transform(channel_data.copy())\n    return transformed_data\n    \ndef apply_random_transformations(channel_data):\n    transformations = [min_max_amplitude_scale, time_shift, dc_shift, zero_masking, add_gaussian_noise]\n    selected_transforms = random.sample(transformations, 2)\n    transformed_data_1 = selected_transforms[0](channel_data.copy())\n    transformed_data_2 = selected_transforms[1](channel_data.copy())\n    return transformed_data_1, transformed_data_2\n    \n    \ndef chunk_data(data, chunk_size=4000):\n    \"\"\"Divide i dati in chunk della dimensione specificata.\"\"\"\n    chunks = []\n    num_chunks = len(data) // chunk_size\n\n    for i in range(num_chunks):\n        start_idx = i * chunk_size\n        end_idx = (i + 1) * chunk_size\n        chunks.append(data[start_idx:end_idx])\n    \n    return chunks","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ConvolutionalEncoder(nn.Module):\n    def __init__(self, input_channels=1, output_dim=4, repeat_blocks=4):\n        super(ConvolutionalEncoder, self).__init__()\n        \n        # Parallel convolutional paths\n        self.conv1d_128 = nn.Sequential(\n            nn.ReflectionPad1d((63, 64)),\n            nn.Conv1d(input_channels, 100, kernel_size=128, stride=1)\n        )\n        self.conv1d_64 = nn.Sequential(\n            nn.ReflectionPad1d((31, 32)),\n            nn.Conv1d(input_channels, 100, kernel_size=64, stride=1)\n        )\n        self.conv1d_16 = nn.Sequential(\n            nn.ReflectionPad1d((7, 8)),\n            nn.Conv1d(input_channels, 50, kernel_size=16, stride=1)\n        )\n\n        # Dense layer to merge paths\n        self.concat_dense = nn.Linear(100 + 100 + 50, 250)\n\n        # Repeat N=4 blocks\n        self.repeat_blocks = nn.ModuleList([\n            nn.Sequential(\n                nn.ReLU(),\n                nn.BatchNorm1d(250),\n                nn.ReflectionPad1d((31, 32)),\n                nn.Conv1d(250, 250, kernel_size=64, stride=1)\n            ) for _ in range(repeat_blocks)\n        ])\n\n        # Final block\n        self.final_relu = nn.ReLU()\n        self.final_bn = nn.BatchNorm1d(250)\n        self.final_conv = nn.Sequential(\n            nn.ReflectionPad1d((31, 32)),\n            nn.Conv1d(250, output_dim, kernel_size=64, stride=1)\n        )\n        \n    def forward(self, x):\n        # Input shape: [batch_size, sequence_length, channels] modify\n\n        \n        x = x.permute(0, 2, 1)  #[batch_size, channels, sequence_length]\n        \n        # Parallel convolutional paths\n        x1 = self.conv1d_128(x)\n        x2 = self.conv1d_64(x)\n        x3 = self.conv1d_16(x)\n\n        # Concatenate paths\n        x_cat = torch.cat([x1, x2, x3], dim=1)  # [batch_size, 250, sequence_length]\n        \n        # Dense layer\n        x_dense = self.concat_dense(x_cat.permute(0, 2, 1)).permute(0, 2, 1)\n\n        # Repeated blocks\n        x_repeated = x_dense\n        for block in self.repeat_blocks:\n            x_repeated = x_repeated + block(x_repeated)  # Residual connection\n\n        # Final block\n        x_final = self.final_relu(x_repeated)\n        x_final = self.final_bn(x_final)\n        x_final = self.final_conv(x_final)\n        x_final = x_final.permute(0, 2, 1)\n        #print(\"xfinal:\", x_final.shape)\n        return x_final  # [batch_size, output_dim]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RecurrentEncoder(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_dim=128, repeat_n=2):\n        super(RecurrentEncoder, self).__init__()\n\n        self.gru_256 = nn.GRU(input_dim, 256, batch_first=True)\n        self.downsample_256_128 = nn.Linear(256, 128)\n        self.gru_128 = nn.GRU(128, 128, batch_first=True)\n        self.downsample_128_64 = nn.Linear(128, 64)\n        self.gru_64 = nn.GRU(64, 64, batch_first=True)\n\n        self.upsample_64_128 = nn.Linear(64, 128)\n        self.upsample_128_256 = nn.Linear(128, 256)\n\n        self.concat_dense = nn.Linear(256 + 128 + 64, hidden_dim)\n\n        self.rru = nn.ModuleList([\n            nn.Sequential(\n                nn.LayerNorm(hidden_dim),\n                nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n            ) for _ in range(repeat_n)\n        ])\n\n        self.output_dense = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x_256, _ = self.gru_256(x)\n        x_128_input = F.relu(self.downsample_256_128(x_256))\n        x_128, _ = self.gru_128(x_128_input)\n        x_64_input = F.relu(self.downsample_128_64(x_128))\n        x_64, _ = self.gru_64(x_64_input)\n\n        x_128_up = F.relu(self.upsample_64_128(x_64))\n        x_256_up = F.relu(self.upsample_128_256(x_128_up))\n\n        x_concat = torch.cat([x_256, x_128, x_64], dim=-1)\n        x_hidden = F.relu(self.concat_dense(x_concat))\n\n        for i, rru_layer in enumerate(self.rru):\n            residual, _ = rru_layer(x_hidden)\n            x_hidden = x_hidden + residual\n\n        output = self.output_dense(x_hidden)\n        return output\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Projector(nn.Module):\n    def __init__(self, input_dim, output_dim=32):\n        super(Projector, self).__init__()\n\n        self.downsample_1 = nn.Linear(input_dim, 256)\n        self.bilstm_256 = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n\n        self.downsample_2 = nn.Linear(256, 128)\n        self.bilstm_128 = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n\n        self.downsample_3 = nn.Linear(128, 64)\n        self.bilstm_64 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n\n        self.concat_dense_1 = nn.Linear(256 + 128 + 64, 128)\n        self.concat_dense_2 = nn.Linear(128, output_dim)\n\n    def forward(self, x):\n        #print(\"Input x:\", x.shape)\n\n        x_256 = F.relu(self.downsample_1(x))\n        #print(\"Output x_256 (Downsample):\", x_256.shape)\n\n        x_256, (h_256, _) = self.bilstm_256(x_256)\n        flo_256 = torch.cat([h_256[0], h_256[1]], dim=-1)\n        #print(\"Output flo_256 (BiLSTM):\", flo_256.shape)\n\n        x_128 = F.relu(self.downsample_2(x_256))\n        #print(\"Output x_128 (Downsample):\", x_128.shape)\n\n        x_128, (h_128, _) = self.bilstm_128(x_128)\n        flo_128 = torch.cat([h_128[0], h_128[1]], dim=-1)\n        #print(\"Output flo_128 (BiLSTM):\", flo_128.shape)\n\n        x_64 = F.relu(self.downsample_3(x_128))\n        #print(\"Output x_64 (Downsample):\", x_64.shape)\n\n        x_64, (h_64, _) = self.bilstm_64(x_64)\n        flo_64 = torch.cat([h_64[0], h_64[1]], dim=-1)\n        #print(\"Output flo_64 (BiLSTM):\", flo_64.shape)\n\n        x_concat = torch.cat([flo_256, flo_128, flo_64], dim=-1)\n        #print(\"Output x_concat (Concat):\", x_concat.shape)\n\n        x_hidden = F.relu(self.concat_dense_1(x_concat))\n        #print(\"Output x_hidden (Dense):\", x_hidden.shape)\n\n        output = self.concat_dense_2(x_hidden)\n        #print(\"Final Output projector:\", output.shape)\n        return output\n        \nclass NTXentLoss(nn.Module):\n    def __init__(self, temperature=0.05):\n        super(NTXentLoss, self).__init__()\n        self.temperature = temperature\n\n    def forward(self, z_i, z_j, z_neg):\n        z_i = F.normalize(z_i, p=2, dim=-1)\n        z_j = F.normalize(z_j, p=2, dim=-1)\n        z_neg = F.normalize(z_neg, p=2, dim=-1)\n\n        # Similarità\n        sim_ij = torch.matmul(z_i, z_j.T) / self.temperature  # Positiva\n        sim_neg = torch.matmul(z_i, z_neg.T) / self.temperature  # Negative\n\n        # Calcolo della loss\n        numerator = torch.exp(sim_ij.diag())\n        denominator = numerator + torch.sum(torch.exp(sim_neg), dim=1)\n\n        loss = -torch.log(numerator / denominator)\n        return loss.mean()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"*****\n","metadata":{}},{"cell_type":"code","source":"class EEGClassificationDataset(Dataset):\n    def __init__(self, file_paths, seq_len=200):\n        self.samples = []\n        self.labels = []\n        self.seq_len = seq_len\n\n        for file_path in file_paths:\n            npz_data = np.load(file_path)\n            data = npz_data['data']  # (num_samples, num_channels, seq_len)\n            label = npz_data['label']  # scalare\n\n            if isinstance(label, np.ndarray):\n                label = label.item()\n\n            # label potrebbe essere -1, 0 o 1. Li rimappiamo in 0, 1, 2.\n            if label == -1:\n                label = 0\n            elif label == 0:\n                label = 1\n            elif label == 1:\n                label = 2\n\n            labels = np.full((data.shape[0],), label)\n\n            # Cambia la forma a (num_samples, seq_len, num_channels)\n            data = data.transpose(0, 2, 1)\n\n            self.samples.extend(data)\n            self.labels.extend(labels)\n\n        class_counts = Counter(self.labels)\n        print(\"Distribuzione delle classi nel dataset:\", class_counts)\n        print(\"Dataset creato con\", len(self.samples), \"segmenti.\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        data = torch.tensor(self.samples[idx], dtype=torch.float32)  # (seq_len, num_channels)\n        label = int(self.labels[idx])\n        return data, label\n\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(Classifier, self).__init__()\n\n        self.downsample_1 = nn.Linear(input_dim, 256)\n        self.bilstm_256 = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n\n        self.downsample_2 = nn.Linear(256, 128)\n        self.bilstm_128 = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n\n        self.downsample_3 = nn.Linear(128, 64)\n        self.bilstm_64 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n\n        self.concat_dense_1 = nn.Linear(256 + 128 + 64, 128)\n        self.concat_dense_2 = nn.Linear(128, num_classes)\n\n        self.log_softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x_256 = F.relu(self.downsample_1(x))\n        x_256, (h_256, _) = self.bilstm_256(x_256)\n        flo_256 = torch.cat([h_256[0], h_256[1]], dim=-1)\n\n        x_128 = F.relu(self.downsample_2(x_256))\n        x_128, (h_128, _) = self.bilstm_128(x_128)\n        flo_128 = torch.cat([h_128[0], h_128[1]], dim=-1)\n\n        x_64 = F.relu(self.downsample_3(x_128))\n        x_64, (h_64, _) = self.bilstm_64(x_64)\n        flo_64 = torch.cat([h_64[0], h_64[1]], dim=-1)\n\n        x_concat = torch.cat([flo_256, flo_128, flo_64], dim=-1)\n        x_hidden = F.relu(self.concat_dense_1(x_concat))\n        output = self.concat_dense_2(x_hidden)\n        return self.log_softmax(output)\n\ndef load_model(model, path, device=\"cuda\"):\n    state_dict = torch.load(path, map_location=device)\n    # Rimuoviamo eventuale prefisso 'module.' se salvato con DataParallel\n    if any(k.startswith('module.') for k in state_dict.keys()):\n        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict)\n    model.to(device)\n\ndef save_model(model, path):\n    if isinstance(model, nn.DataParallel):\n        model = model.module\n    torch.save(model.state_dict(), path)\n\ndef train_classifier(model_type, file_paths, encoder, classifier, optimizer, epochs=1, batch_size=40, device=\"cuda\"):\n    dataset = EEGClassificationDataset(file_paths)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n\n    encoder.eval()\n    for param in encoder.parameters():\n        param.requires_grad = False\n    encoder = nn.DataParallel(encoder).to(device)\n\n    classifier = nn.DataParallel(classifier).to(device)\n    classifier.train()\n    loss_fn = nn.NLLLoss()\n\n    save_path = \"./model_checkpoints\"\n    os.makedirs(save_path, exist_ok=True)\n\n    for epoch in range(epochs):\n        print(f\"=== Inizio Epoca {epoch + 1}/{epochs} ===\")\n        total_loss = 0\n        correct_predictions = 0\n        total_predictions = 0\n\n        for batch_idx, (data, labels) in enumerate(dataloader):\n            #print(f\"Batch {batch_idx + 1}: Shape data: {data.shape}, Shape labels: {labels.shape}\")\n            data, labels = data.to(device), labels.to(device)\n\n            batch_outputs = []\n            # Itera sui canali\n            for channel_idx in range(data.shape[2]):\n                channel_data = data[:, :, channel_idx].unsqueeze(-1)  # (batch_size, seq_len, 1)\n                with torch.no_grad():\n                    channel_output = encoder(channel_data)  # (batch_size, seq_len, 4)\n                batch_outputs.append(channel_output)\n\n            # Concateniamo le feature di tutti i canali\n            embeddings = torch.cat(batch_outputs, dim=-1)  # (batch_size, seq_len, 4*num_channels)\n            #print(\"Embeddings shape:\", embeddings.shape)\n\n            logits = classifier(embeddings)\n            loss = loss_fn(logits, labels)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            _, predicted = torch.max(logits, 1)\n            correct_predictions += (predicted == labels).sum().item()\n            total_predictions += labels.size(0)\n\n            if batch_idx % 10 == 0:\n                accuracy = 100 * correct_predictions / total_predictions\n                print(f\"Epoca {epoch + 1}/{epochs}, Batch {batch_idx + 1}/{len(dataloader)}, Perdita: {loss.item():.4f}, Accuratezza: {accuracy:.2f}%\")\n\n        epoch_accuracy = 100 * correct_predictions / total_predictions\n        print(f\"Epoca {epoch + 1}/{epochs}, Perdita Totale: {total_loss:.4f}, Accuratezza: {epoch_accuracy:.2f}%\")\n        save_model(classifier, os.path.join(save_path, f\"classifier_{model_type}_epoch_{epoch + 1}.pt\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    folder_path = \"/kaggle/working/train_set\"\n    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npz')]\n\n    encoder = RecurrentEncoder(input_dim=1, output_dim=4)\n    load_model(encoder, \"/kaggle/input/recurrent_encoder_/pytorch/default/1/Recurrent_epoch_24.pth\", device=\"cuda\")\n\n    # Il numero di canali è 20 e l'encoder produce 4 feature per canale: input_dim=4*num_channels=4*20=80\n    classifier = Classifier(input_dim=4 * 20, num_classes=3)\n    optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n\n    train_classifier(\"Recurrent\", file_paths, encoder, classifier, optimizer, epochs=10, batch_size=40, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    folder_path = \"/kaggle/working/train_set\"\n    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npz')]\n\n    encoder = ConvolutionalEncoder(input_channels=1, output_dim=4)\n    load_model(encoder, \"/kaggle/input/convolutional_encoder/pytorch/default/1/Convolutional_epoch_10.pth\", device=\"cuda\")\n\n    # Il numero di canali è 20 e l'encoder produce 4 feature per canale: input_dim=4*num_channels=4*20=80\n    classifier = Classifier(input_dim=4 * 20, num_classes=3)\n    optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n\n    train_classifier(\"Convolutional\", file_paths, encoder, classifier, optimizer, epochs=10, batch_size=40, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EVALUATION**","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom collections import Counter\n\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n\nclass EEGEvaluationDataset(Dataset):\n    def __init__(self, file_paths, seq_len=200):\n        self.samples = []\n        self.labels = []\n        self.seq_len = seq_len\n\n        for file_path in file_paths:\n            npz_data = np.load(file_path)\n            data = npz_data['data']  # (num_samples, num_channels, seq_len)\n            label = npz_data['label']  \n\n            if isinstance(label, np.ndarray):\n                label = label.item()\n\n            if label == -1:\n                label = 0\n            elif label == 0:\n                label = 1\n            elif label == 1:\n                label = 2\n\n            labels = np.full((data.shape[0],), label)\n\n            # Cambia forma a (num_samples, seq_len, num_channels)\n            data = data.transpose(0, 2, 1)\n\n            self.samples.extend(data)\n            self.labels.extend(labels)\n\n        class_counts = Counter(self.labels)\n        print(\"Distribuzione delle classi nel dataset (test):\", class_counts)\n        print(\"Test set creato con\", len(self.samples), \"segmenti.\")\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        data = torch.tensor(self.samples[idx], dtype=torch.float32)  # (seq_len, num_channels)\n        label = int(self.labels[idx])\n        return data, label\n\nclass Classifier(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(Classifier, self).__init__()\n\n        self.downsample_1 = nn.Linear(input_dim, 256)\n        self.bilstm_256 = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n\n        self.downsample_2 = nn.Linear(256, 128)\n        self.bilstm_128 = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n\n        self.downsample_3 = nn.Linear(128, 64)\n        self.bilstm_64 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n\n        self.concat_dense_1 = nn.Linear(256 + 128 + 64, 128)\n        self.concat_dense_2 = nn.Linear(128, num_classes)\n\n        self.log_softmax = nn.LogSoftmax(dim=1)\n\n    def forward(self, x):\n        x_256 = F.relu(self.downsample_1(x))\n        x_256, (h_256, _) = self.bilstm_256(x_256)\n        flo_256 = torch.cat([h_256[0], h_256[1]], dim=-1)\n\n        x_128 = F.relu(self.downsample_2(x_256))\n        x_128, (h_128, _) = self.bilstm_128(x_128)\n        flo_128 = torch.cat([h_128[0], h_128[1]], dim=-1)\n\n        x_64 = F.relu(self.downsample_3(x_128))\n        x_64, (h_64, _) = self.bilstm_64(x_64)\n        flo_64 = torch.cat([h_64[0], h_64[1]], dim=-1)\n\n        x_concat = torch.cat([flo_256, flo_128, flo_64], dim=-1)\n        x_hidden = F.relu(self.concat_dense_1(x_concat))\n        output = self.concat_dense_2(x_hidden)\n        return self.log_softmax(output)\n\ndef load_model(model, path, device=\"cuda\"):\n    state_dict = torch.load(path, map_location=device)\n    if any(k.startswith('module.') for k in state_dict.keys()):\n        state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict)\n    model.to(device)\n\ndef evaluate_classifier(file_paths, encoder, classifier,batch_size=40, device=\"cuda\"):\n    dataset = EEGEvaluationDataset(file_paths)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, drop_last=False)\n\n    encoder.eval()\n    classifier.eval()\n\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for data, labels in dataloader:\n            data, labels = data.to(device), labels.to(device)\n\n            batch_outputs = []\n            for channel_idx in range(data.shape[2]):\n                channel_data = data[:, :, channel_idx].unsqueeze(-1)  # (batch_size, seq_len, 1)\n                channel_output = encoder(channel_data)  # (batch_size, seq_len, 4)\n                batch_outputs.append(channel_output)\n\n            embeddings = torch.cat(batch_outputs, dim=-1)  # (batch_size, seq_len, 4*num_channels)\n            logits = classifier(embeddings)\n            _, predicted = torch.max(logits, 1)\n\n            all_preds.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    # Calcolo metriche\n    acc = accuracy_score(all_labels, all_preds)\n    cm = confusion_matrix(all_labels, all_preds)\n    report = classification_report(all_labels, all_preds, digits=4)\n\n    print(\"=== Risultati sul Test Set ===\")\n    print(\"Accuratezza:\", acc)\n    print(\"Matrice di Confusione:\")\n    print(cm)\n    print(\"Report di Classificazione (Precision, Recall, F1-Score):\")\n    print(report)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_folder_path = \"/kaggle/working/test_set\"\n    test_file_paths = [os.path.join(test_folder_path, f) for f in os.listdir(test_folder_path) if f.endswith('.npz')]\n    \n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n\n    encoder = RecurrentEncoder(input_dim=1, output_dim=4)  \n    classifier = Classifier(input_dim=4 * 20, num_classes=3)\n\n    load_model(encoder, \"/kaggle/input/recurrent_encoder_/pytorch/default/1/Recurrent_epoch_24.pth\", device=device)\n    load_model(classifier, \"/kaggle/input/classifier_recurrent/pytorch/default/1/classifier_Recurrent_epoch_10.pt\", device=device)\n\n    evaluate_classifier(test_file_paths, encoder, classifier,batch_size=40, device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    test_folder_path = \"/kaggle/working/test_set\"\n    test_file_paths = [os.path.join(test_folder_path, f) for f in os.listdir(test_folder_path) if f.endswith('.npz')]\n    \n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n    # Carica i modelli già addestrati\n    encoder = ConvolutionalEncoder(input_channels=1, output_dim=4) \n    classifier = Classifier(input_dim=4 * 20, num_classes=3)  \n\n    load_model(encoder, \"/kaggle/input/convolutional_encoder/pytorch/default/1/Convolutional_epoch_10.pth\", device=device)\n    load_model(classifier, \"/kaggle/input/classifier_convolutional/pytorch/default/1/classifier_Convolutional_epoch_10.pt\", device=device)\n\n    evaluate_classifier(test_file_paths, encoder, classifier,batch_size=40, device=device)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}