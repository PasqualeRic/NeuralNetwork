{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10190077,"sourceType":"datasetVersion","datasetId":6295778},{"sourceId":10190185,"sourceType":"datasetVersion","datasetId":6295862},{"sourceId":10196847,"sourceType":"datasetVersion","datasetId":6300532}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport glob\nfrom scipy.signal import butter, filtfilt\nfrom scipy.signal import resample_poly\nimport librosa\nfrom scipy.io import loadmat\nimport warnings\nfrom scipy.io import savemat\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FASE DI PREPROCESSING E REORDERING DEI FILE IN COLONNE**","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"code","source":"#riduzione dataset seed\n\ninput_path = '/kaggle/input/seed-dataset/Preprocessed_EEG'\noutput_path = '/kaggle/working/reduced_dataset'\n\n\n# Crea la cartella di output\nos.makedirs(output_path, exist_ok=True)\n\n# Parametri per la riduzione\nchannel_reduction_ratio = 3  # Dividi il numero di canali per 3\nsample_reduction_ratio = 2   # Dividi il numero di campioni per 2\n\nmat_files = [f for f in os.listdir(input_path) if f.endswith('.mat') and f != 'label.mat']\nprint(f\"Trovati {len(mat_files)} file .mat nella directory.\")\n\nfor file_name in mat_files:\n    file_path = os.path.join(input_path, file_name)\n    print(f\"Processando il file: {file_name}\")\n    \n\n    mat_data = loadmat(file_path)\n    \n    # Trova tutte le chiavi che rappresentano trial (chiavi con strutture comuni come djc_eeg, ys_eeg, ecc.)\n    trial_keys = [key for key in sorted(mat_data.keys()) if not key.startswith('__') and isinstance(mat_data[key], np.ndarray)]\n    print(f\"Trial trovati in {file_name}: {trial_keys}\")\n    \n    if not trial_keys:\n        print(f\"Nessun trial trovato in {file_name}, salto il file.\")\n        continue\n    \n    # Seleziona casualmente un terzo dei trial\n    random.seed(42)\n    selected_keys = random.sample(trial_keys, len(trial_keys) // 3)\n    \n    for key in selected_keys:  # Itera SOLO sui trial selezionati\n        data = mat_data[key]\n        \n        # Riduzione del numero di canali\n        num_channels = data.shape[0]\n        reduced_channels = num_channels // channel_reduction_ratio\n        reduced_data = data[:reduced_channels, :]\n        \n        # Riduzione del numero di campioni\n        num_samples = reduced_data.shape[1]\n        reduced_samples = num_samples // sample_reduction_ratio\n        reduced_data = reduced_data[:, :reduced_samples]\n        \n        # Salva i dati ridotti\n        output_file = os.path.join(output_path, f\"{file_name.replace('.mat', '')}_{key}.npz\")\n        np.savez(output_file, data=reduced_data)\n\nprint(f\"Dataset ridotto salvato in: {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#preprocessamento dataset seed\n\nfolder_path = '/kaggle/working/reduced_dataset'\nfile_paths = glob.glob(f\"{folder_path}/*.npz\")\nfolder1_path = '/kaggle/working/preprocessed'\nos.makedirs(folder1_path, exist_ok=True)\n\nwarnings.filterwarnings(\"ignore\")\n\n# Funzione per il filtro band-pass Butterworth\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n# Funzione per plottare i segnali\ndef plot_signals(original_signal, cleaned_signal, channel_idx, file_name):\n    plt.figure(figsize=(15, 10))\n\n    plt.subplot(2, 1, 1)\n    plt.plot(original_signal, label='Originale', color='blue')\n    plt.title(f\"{file_name} - Canale {channel_idx} (Originale)\")\n    plt.xlabel(\"Campioni\")\n    plt.ylabel(\"Ampiezza\")\n    plt.legend()\n\n    plt.subplot(2, 1, 2)\n    plt.plot(cleaned_signal, label='Pulito (±500 µV)', color='red')\n    plt.title(f\"{file_name} - Canale {channel_idx} (Pulito)\")\n    plt.xlabel(\"Campioni\")\n    plt.ylabel(\"Ampiezza\")\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\n\nfor file_path in file_paths:\n    try:\n        # Carica il file .mat\n        file_name = os.path.basename(file_path).replace('.npz', '')\n        print(f\"Processando il file: {file_name}\")\n\n        npz_data = np.load(file_path)\n        \n        # Itera sulle chiavi del file .npz\n        for key in npz_data.keys():\n            data = npz_data[key]\n            print(f\"Elaborazione della chiave: {key} - Forma: {data.shape}\")\n            \n\n            # Preprocessing dei canali\n            processed_channels = []\n            for channel_idx in range(data.shape[0]):\n                original_signal = data[channel_idx, :]\n\n                # Rimozione valori superiori a ±500 µV\n                cleaned_signal = original_signal.copy()\n                cleaned_signal[np.abs(cleaned_signal) > 500] = 0  # Sostituisci con 0\n\n                #plot_signals_all_channels(original_signal, cleaned_signal, channel_idx, file_name)\n\n                processed_channels.append(cleaned_signal)\n\n            processed_data = np.array(processed_channels)\n            print(f\"Dati processati per la chiave {key}: forma {processed_data.shape}\")\n\n            output_path = os.path.join(folder1_path, f\"processed_{file_name}_{key}.npy\")\n            np.save(output_path, processed_data)\n            print(f\"Dati salvati in formato NumPy: {output_path}\")\n\n    except Exception as e:\n        print(f\"Errore durante il preprocessing del file {file_path}: {e}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Preprocessamento dataset dataverse\n# Funzione per il filtro band-pass Butterworth\ndef butter_bandpass(lowcut, highcut, fs, order=5):\n    nyquist = 0.5 * fs\n    low = lowcut / nyquist\n    high = highcut / nyquist\n    b, a = butter(order, [low, high], btype='band')\n    return b, a\n\n# Funzione per applicare il filtro ai dati\ndef butter_filter(data, lowcut, highcut, fs, order=5):\n    b, a = butter_bandpass(lowcut, highcut, fs, order)\n    return filtfilt(b, a, data)\n\n# Funzione per il resampling usando librosa\ndef librosa_resample(data, original_fs, target_fs):\n    # Controlla e gestisce NaN o inf nel segnale\n    data = np.nan_to_num(data)  # Sostituisci NaN con 0 e inf con valori finiti\n    return librosa.resample(data, orig_sr=original_fs, target_sr=target_fs, res_type='soxr_hq')\n\n\nfolder_path = '/kaggle/input/dataverse-files/dataverse_files'\nfolder1_path = '/kaggle/working/preprocessed'\n#os.makedirs(folder1_path, exist_ok=True)\n\n\nfile_paths = glob.glob(os.path.join(folder_path, '*.txt'))\n\n# Parametri di frequenza di campionamento target\ntarget_fs = 200  # Frequenza di campionamento desiderata\noriginal_fs = 256\n# Parametri per il filtro Butterworth\nlowcut = 0.3\nhighcut = 80.0\n\n# Durata del segnale in secondi\nsignal_duration = 20  # Preso dal paper, scelgono dataset con 20 sec\n\nfor file_path in file_paths:\n\n    file_name = os.path.basename(file_path).replace('.txt', '')\n    print(f\"Processando il file: {file_name}\")\n\n\n    data = pd.read_csv(file_path, sep='\\t', header=None)\n\n    cleaned_signals = []\n    for channel_idx in range(data.shape[1]):\n        original_signal = data.iloc[:, channel_idx].values  # Estrarre il segnale come array Numpy\n\n        # Rimozione di eventuali valori non numerici prima del resampling\n        original_signal = np.nan_to_num(original_signal)\n\n        # Resampling usando librosa\n        resampled_signal = librosa_resample(original_signal, original_fs, target_fs)\n\n        # Filtraggio\n        filtered_signal = butter_filter(resampled_signal, lowcut, highcut, target_fs)\n\n        # Rimozione valori ±500 µV\n        cleaned_signal = filtered_signal.copy()\n        cleaned_signal[np.abs(cleaned_signal) > 500] = np.nan  # Sostituisci con NaN\n        cleaned_signal = pd.Series(cleaned_signal).interpolate().fillna(0).values  # Interpolazione per riempire i vuoti\n        cleaned_signals.append(cleaned_signal)\n    # Converte i canali preprocessati in un array NumPy\n    cleaned_data = np.array(cleaned_signals)\n    print(f\"Dati processati forma {cleaned_data.shape}\")\n    output_path = os.path.join(folder1_path, f\"preprocessing_{file_name}.npy\")\n    np.save(output_path, cleaned_data)\n    print(f\"File con preprocessing salvato come npy: {output_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ------------------- Funzioni per Salvare e Caricare Modelli -------------------\nsave_path = \"/kaggle/working/models\"\nos.makedirs(save_path, exist_ok=True)\n\ndef save_model(model, path):\n    torch.save(model.state_dict(), path)\n    print(f\"Modello salvato in {path}\")\n\n\n#tolgo il module \ndef load_model(model, path, device=\"cuda\"):\n    state_dict = torch.load(path, map_location=device)\n    if \"module.\" in list(state_dict.keys())[0]:\n        state_dict = {k.replace(\"module.\", \"\"): v for k, v in state_dict.items()}\n    model.load_state_dict(state_dict)\n    print(f\"Modello caricato da {path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FASE DI TRAINING DELL'ENCODER RICORRENTE E CONVOLUZIONALE**","metadata":{}},{"cell_type":"markdown","source":"********","metadata":{}},{"cell_type":"code","source":"#AUGMENTATION E CHUNK DATI\ndef min_max_amplitude_scale(data, scale_min=0.5, scale_max=2):\n    scale_factor = random.uniform(scale_min, scale_max)\n    return data * scale_factor\n\ndef time_shift(data, shift_min=-50, shift_max=50):\n    shift_samples = random.randint(shift_min, shift_max)\n    return np.roll(data, shift_samples)\n\ndef dc_shift(data, shift_min=-10, shift_max=10):\n    shift_value = random.uniform(shift_min, shift_max)\n    return data + shift_value\n\ndef zero_masking(data, mask_min=0, mask_max=150):\n    mask_size = random.randint(mask_min, mask_max)\n    start_idx = random.randint(0, len(data) - mask_size)\n    data[start_idx:start_idx+mask_size] = 0\n    return data\n\ndef add_gaussian_noise(data, sigma_min=0, sigma_max=0.2):\n    sigma = random.uniform(sigma_min, sigma_max)\n    noise = np.random.normal(0, sigma, len(data))\n    return data + noise\n\ndef apply_random_transformations_class(channel_data):\n    transformations = [min_max_amplitude_scale, time_shift, dc_shift, zero_masking, add_gaussian_noise]\n    selected_transform = random.choice(transformations)\n    transformed_data = selected_transform(channel_data.copy())\n    return transformed_data\n    \ndef apply_random_transformations(channel_data):\n    transformations = [min_max_amplitude_scale, time_shift, dc_shift, zero_masking, add_gaussian_noise]\n    selected_transforms = random.sample(transformations, 2)\n    transformed_data_1 = selected_transforms[0](channel_data.copy())\n    transformed_data_2 = selected_transforms[1](channel_data.copy())\n    return transformed_data_1, transformed_data_2\n    \n    \ndef chunk_data(data, chunk_size=4000):\n    \"\"\"Divide i dati in chunk della dimensione specificata.\"\"\"\n    chunks = []\n    num_chunks = len(data) // chunk_size\n\n    for i in range(num_chunks):\n        start_idx = i * chunk_size\n        end_idx = (i + 1) * chunk_size\n        chunks.append(data[start_idx:end_idx])\n    \n    return chunks\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ConvolutionalEncoder(nn.Module):\n    def __init__(self, input_channels=1, output_dim=4, repeat_blocks=4):\n        super(ConvolutionalEncoder, self).__init__()\n        \n        # Parallel convolutional paths\n        self.conv1d_128 = nn.Sequential(\n            nn.ReflectionPad1d((63, 64)),\n            nn.Conv1d(input_channels, 100, kernel_size=128, stride=1)\n        )\n        self.conv1d_64 = nn.Sequential(\n            nn.ReflectionPad1d((31, 32)),\n            nn.Conv1d(input_channels, 100, kernel_size=64, stride=1)\n        )\n        self.conv1d_16 = nn.Sequential(\n            nn.ReflectionPad1d((7, 8)),\n            nn.Conv1d(input_channels, 50, kernel_size=16, stride=1)\n        )\n\n        # Dense layer to merge paths\n        self.concat_dense = nn.Linear(100 + 100 + 50, 250)\n\n        # Repeat N=4 blocks\n        self.repeat_blocks = nn.ModuleList([\n            nn.Sequential(\n                nn.ReLU(),\n                nn.BatchNorm1d(250),\n                nn.ReflectionPad1d((31, 32)),\n                nn.Conv1d(250, 250, kernel_size=64, stride=1)\n            ) for _ in range(repeat_blocks)\n        ])\n\n        # Final block\n        self.final_relu = nn.ReLU()\n        self.final_bn = nn.BatchNorm1d(250)\n        self.final_conv = nn.Sequential(\n            nn.ReflectionPad1d((31, 32)),\n            nn.Conv1d(250, output_dim, kernel_size=64, stride=1)\n        )\n        \n    def forward(self, x):\n        # Input shape: [batch_size, sequence_length, channels] modify\n\n        \n        x = x.permute(0, 2, 1)  #[batch_size, channels, sequence_length]\n        \n        # Parallel convolutional paths\n        x1 = self.conv1d_128(x)\n        x2 = self.conv1d_64(x)\n        x3 = self.conv1d_16(x)\n\n        # Concatenate paths\n        x_cat = torch.cat([x1, x2, x3], dim=1)  # [batch_size, 250, sequence_length]\n        \n        # Dense layer\n        x_dense = self.concat_dense(x_cat.permute(0, 2, 1)).permute(0, 2, 1)\n\n        # Repeated blocks\n        x_repeated = x_dense\n        for block in self.repeat_blocks:\n            x_repeated = x_repeated + block(x_repeated)  # Residual connection\n\n        # Final block\n        x_final = self.final_relu(x_repeated)\n        x_final = self.final_bn(x_final)\n        x_final = self.final_conv(x_final)\n        x_final = x_final.permute(0, 2, 1)\n        #print(\"xfinal:\", x_final.shape)\n        return x_final  # [batch_size, output_dim]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class RecurrentEncoder(nn.Module):\n    def __init__(self, input_dim, output_dim, hidden_dim=128, repeat_n=2):\n        super(RecurrentEncoder, self).__init__()\n\n        self.gru_256 = nn.GRU(input_dim, 256, batch_first=True)\n        self.downsample_256_128 = nn.Linear(256, 128)\n        self.gru_128 = nn.GRU(128, 128, batch_first=True)\n        self.downsample_128_64 = nn.Linear(128, 64)\n        self.gru_64 = nn.GRU(64, 64, batch_first=True)\n\n        self.upsample_64_128 = nn.Linear(64, 128)\n        self.upsample_128_256 = nn.Linear(128, 256)\n\n        self.concat_dense = nn.Linear(256 + 128 + 64, hidden_dim)\n\n        self.rru = nn.ModuleList([\n            nn.Sequential(\n                nn.LayerNorm(hidden_dim),\n                nn.GRU(hidden_dim, hidden_dim, batch_first=True)\n            ) for _ in range(repeat_n)\n        ])\n\n        self.output_dense = nn.Linear(hidden_dim, output_dim)\n\n    def forward(self, x):\n        x_256, _ = self.gru_256(x)\n        x_128_input = F.relu(self.downsample_256_128(x_256))\n        x_128, _ = self.gru_128(x_128_input)\n        x_64_input = F.relu(self.downsample_128_64(x_128))\n        x_64, _ = self.gru_64(x_64_input)\n\n        x_128_up = F.relu(self.upsample_64_128(x_64))\n        x_256_up = F.relu(self.upsample_128_256(x_128_up))\n\n        x_concat = torch.cat([x_256, x_128, x_64], dim=-1)\n        x_hidden = F.relu(self.concat_dense(x_concat))\n\n        for i, rru_layer in enumerate(self.rru):\n            residual, _ = rru_layer(x_hidden)\n            x_hidden = x_hidden + residual\n\n        output = self.output_dense(x_hidden)\n        return output\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Projector(nn.Module):\n    def __init__(self, input_dim, output_dim=32):\n        super(Projector, self).__init__()\n\n        self.downsample_1 = nn.Linear(input_dim, 256)\n        self.bilstm_256 = nn.LSTM(256, 128, batch_first=True, bidirectional=True)\n\n        self.downsample_2 = nn.Linear(256, 128)\n        self.bilstm_128 = nn.LSTM(128, 64, batch_first=True, bidirectional=True)\n\n        self.downsample_3 = nn.Linear(128, 64)\n        self.bilstm_64 = nn.LSTM(64, 32, batch_first=True, bidirectional=True)\n\n        self.concat_dense_1 = nn.Linear(256 + 128 + 64, 128)\n        self.concat_dense_2 = nn.Linear(128, output_dim)\n\n    def forward(self, x):\n        #print(\"Input x:\", x.shape)\n\n        x_256 = F.relu(self.downsample_1(x))\n        #print(\"Output x_256 (Downsample):\", x_256.shape)\n\n        x_256, (h_256, _) = self.bilstm_256(x_256)\n        flo_256 = torch.cat([h_256[0], h_256[1]], dim=-1)\n        #print(\"Output flo_256 (BiLSTM):\", flo_256.shape)\n\n        x_128 = F.relu(self.downsample_2(x_256))\n        #print(\"Output x_128 (Downsample):\", x_128.shape)\n\n        x_128, (h_128, _) = self.bilstm_128(x_128)\n        flo_128 = torch.cat([h_128[0], h_128[1]], dim=-1)\n        #print(\"Output flo_128 (BiLSTM):\", flo_128.shape)\n\n        x_64 = F.relu(self.downsample_3(x_128))\n        #print(\"Output x_64 (Downsample):\", x_64.shape)\n\n        x_64, (h_64, _) = self.bilstm_64(x_64)\n        flo_64 = torch.cat([h_64[0], h_64[1]], dim=-1)\n        #print(\"Output flo_64 (BiLSTM):\", flo_64.shape)\n\n        x_concat = torch.cat([flo_256, flo_128, flo_64], dim=-1)\n        #print(\"Output x_concat (Concat):\", x_concat.shape)\n\n        x_hidden = F.relu(self.concat_dense_1(x_concat))\n        #print(\"Output x_hidden (Dense):\", x_hidden.shape)\n\n        output = self.concat_dense_2(x_hidden)\n        #print(\"Final Output projector:\", output.shape)\n        return output\n        \nclass NTXentLoss(nn.Module):\n    def __init__(self, temperature=0.05):\n        super(NTXentLoss, self).__init__()\n        self.temperature = temperature\n\n    def forward(self, z_i, z_j, z_neg):\n        z_i = F.normalize(z_i, p=2, dim=-1)\n        z_j = F.normalize(z_j, p=2, dim=-1)\n        z_neg = F.normalize(z_neg, p=2, dim=-1)\n\n        # Similarità\n        sim_ij = torch.matmul(z_i, z_j.T) / self.temperature  # Positiva\n        sim_neg = torch.matmul(z_i, z_neg.T) / self.temperature  # Negative\n\n        # Calcolo della loss\n        numerator = torch.exp(sim_ij.diag())\n        denominator = numerator + torch.sum(torch.exp(sim_neg), dim=1)\n\n        loss = -torch.log(numerator / denominator)\n        return loss.mean()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#------------------ SEED ENCODER ---------------\nimport matplotlib.pyplot as plt\n\n# Funzione per plottare segnali trasformati e negativi\ndef plot_transformed_chunks(data1, data2, negative, idx):\n    plt.figure(figsize=(15, 5))\n\n    # Plotta il primo chunk trasformato\n    plt.subplot(1, 3, 1)\n    plt.plot(data1.squeeze().cpu().numpy(), label='Trasformazione 1', color='blue')\n    plt.title(f'Trasformazione 1 - Chunk {idx}')\n    plt.xlabel('Campioni')\n    plt.ylabel('Ampiezza')\n    plt.legend()\n\n    # Plotta il secondo chunk trasformato\n    plt.subplot(1, 3, 2)\n    plt.plot(data2.squeeze().cpu().numpy(), label='Trasformazione 2', color='green')\n    plt.title(f'Trasformazione 2 - Chunk {idx}')\n    plt.xlabel('Campioni')\n    plt.ylabel('Ampiezza')\n    plt.legend()\n\n    # Plotta il chunk negativo\n    plt.subplot(1, 3, 3)\n    plt.plot(negative.squeeze().cpu().numpy(), label='Chunk Negativo', color='red')\n    plt.title(f'Chunk Negativo - Chunk {idx}')\n    plt.xlabel('Campioni')\n    plt.ylabel('Ampiezza')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n\nclass CompleteContrastiveDataset(Dataset):\n    def __init__(self, file_paths, chunk_size=4000):\n        self.all_chunks = []  # Contiene tutti i chunk\n        self.chunk_sources = []  # Contiene il file di origine di ogni chunk\n\n        for file_path in file_paths:\n            # Carica il file NumPy\n            data = np.load(file_path)\n\n            # Dividi ogni canale in chunk\n            for channel_idx in range(data.shape[0]):  # Itera su tutti i canali\n                channel_data = data[channel_idx]\n                chunks = chunk_data(channel_data, chunk_size)\n\n                # Aggiungi i chunk e le loro sorgenti\n                self.all_chunks.extend(chunks)\n                self.chunk_sources.extend([file_path] * len(chunks))\n\n        print(f\"Dataset creato con {len(self.all_chunks)} chunk totali.\")\n\n    def __len__(self):\n        return len(self.all_chunks)\n\n    def __getitem__(self, idx):\n        # Chunk corrispondente\n        chunk = self.all_chunks[idx]\n        source_file = self.chunk_sources[idx]\n\n        # Crea trasformazioni per le coppie positive\n        transformed_1, transformed_2 = apply_random_transformations(chunk)\n\n        # Seleziona un chunk negativo proveniente da un file diverso\n        possible_negatives = [\n            i for i, src in enumerate(self.chunk_sources) if src != source_file\n        ]\n        neg_idx = random.choice(possible_negatives)\n        negative_chunk = self.all_chunks[neg_idx]\n\n        data1 = torch.tensor(transformed_1, dtype=torch.float32).unsqueeze(-1)\n        data2 = torch.tensor(transformed_2, dtype=torch.float32).unsqueeze(-1)\n        negative = torch.tensor(negative_chunk, dtype=torch.float32).unsqueeze(-1)\n\n        return data1, data2, negative\n\n\n\n# ------------------- Funzione di Addestramento -------------------\ndef train_contrastive_learning(model_type, file_paths, encoder, projector, optimizer, epochs=10, batch_size=10, device=\"cuda\"):\n    loss_fn = NTXentLoss()\n\n    \n    dataset = CompleteContrastiveDataset(file_paths, chunk_size=4000)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n    \n    # Parallelizzazione su più GPU\n    encoder = nn.DataParallel(encoder)\n    projector = nn.DataParallel(projector)\n    encoder.to(device)\n    projector.to(device)\n\n    for epoch in range(epochs):\n        print(f\"=== Epoca {epoch + 1}/{epochs} ===\")\n        total_loss = 0\n\n        for batch_idx, (data1, data2, neg_data) in enumerate(dataloader):\n            data1, data2, neg_data= (\n                data1.to(device),\n                data2.to(device),\n                neg_data.to(device),\n            )\n\n            # Passaggio attraverso encoder e projector\n            z1 = projector(encoder(data1))\n            z2 = projector(encoder(data2))\n            z_neg = projector(encoder(neg_data))\n\n            # Calcolo della loss\n            loss = loss_fn(z1, z2, z_neg)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n            print(f\"Batch {batch_idx + 1}/{len(dataloader)}, Perdita: {loss.item():.4f}\")\n            #plot_transformed_chunks(data1[batch_idx], data2[batch_idx], neg_data[batch_idx], idx=batch_idx)\n\n        print(f\"Perdita totale per epoca {epoch + 1}: {total_loss:.4f}\")\n        save_model(encoder, os.path.join(save_path, f\"{model_type}_epoch_{epoch + 1}.pth\"))\n        save_model(projector, os.path.join(save_path, f\"projector_{model_type}_epoch_{epoch + 1}.pth\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Esecuzione recurrent encoder training\n\nif __name__ == \"__main__\":\n    folder_path = \"/kaggle/working/preprocessed\"\n    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npy')]\n\n    encoder = RecurrentEncoder(input_dim=1, output_dim=4)\n    projector = Projector(input_dim=4, output_dim=32)\n\n    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(projector.parameters()), lr=1e-4)\n    train_contrastive_learning( \"Recurrent\", file_paths, encoder, projector, optimizer, epochs=30, batch_size= 40, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Esecuzione covnolutional encoder training\nif __name__ == \"__main__\":\n    folder_path = \"/kaggle/working/preprocessed\" \n    file_paths = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.npy')]\n\n    encoder = ConvolutionalEncoder(input_channels=1, output_dim=4)\n    projector = Projector(input_dim=4, output_dim=32)\n\n    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(projector.parameters()), lr=1e-4)\n\n    train_contrastive_learning(\"Convolutional\", file_paths, encoder, projector, optimizer, epochs=30, batch_size=40, device=\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}